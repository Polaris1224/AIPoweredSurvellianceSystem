# ðŸ›°ï¸ AIâ€‘Powered Surveillance â€” Streamlit App

**Realâ€‘time person detection, tracking, and shortâ€‘term behaviour anomaly classification** using **YOLO (Ultralytics)**, **DeepSORT**, and a lightweight **MobileNetV2 + LSTM** temporal model.

---

## ðŸš€ Quick overview

* Detect people in video frames with YOLO and track IDs with DeepSORT.
* Extract perâ€‘track crops and run a shortâ€‘term temporal classifier (MobileNetV2 features â†’ LSTM) to flag anomalous behaviour.
* Streamlit UI for easy upload, preview, live labeling, alert log, and optional redâ€‘frame flash on anomalies.
* Designed for **memoryâ€‘safe training** with `tf.data` sliding windows and runs on **CPU** (GPU optional).

---

## ðŸ“ Project structure

```
ai-surveillance/
â”œâ”€ app.py                    # Streamlit UI + inference loop
â”œâ”€ behavior_model.py         # Model architecture (MobileNetV2 + LSTM) wrapper
â”œâ”€ detection.py              # YOLO + DeepSORT glue code
â”œâ”€ train_dataset.py          # Training pipeline / tf.data sliding windows
â”œâ”€ utils.py                  # I/O, video helpers, crop & tracking utilities
â”œâ”€ requirements.txt
â”œâ”€ Dockerfile
â”œâ”€ .dockerignore
â””â”€ data/
   â”œâ”€ training_videos/       # input videos (you add)
   â”œâ”€ training_vol/          # paired .mat files (you add)
   â””â”€ models/
      â”œâ”€ behavior_model.weights.h5
      â””â”€ behavior_model_config.json
```

---

## âœ¨ Features

* âœ… Person detection with Ultralytics YOLO
* âœ… Multiâ€‘object tracking with DeepSORT (perâ€‘ID track history)
* âœ… Temporal behaviour classifier (perâ€‘track short clips) using MobileNetV2 â†’ LSTM
* âœ… Streamlit UI: upload, preview, perâ€‘ID labels, alert log
* âœ… Optional redâ€‘frame flash when anomaly detected
* âœ… Memoryâ€‘safe dataset creation via `tf.data` sliding windows
* âœ… Crossâ€‘platform: Windows / macOS / Linux (Python 3.10)
* âœ… Docker (CPU) friendly; optional GPU path for acceleration

---

## ðŸ› ï¸ Requirements

* Python **3.10.x** (64â€‘bit)
* Packages: see `requirements.txt`
* Optional: Docker Desktop (to run containerized CPU image)

> If you plan to use GPU later, install TensorFlow with GPU support and the appropriate CUDA/cuDNN matching TF 2.15.

---

## ðŸ§© Installation (local, without Docker)

1. Create & activate a virtual environment

**Windows (PowerShell)**

```powershell
py -3.10 -m venv env
.\env\Scripts\Activate
```

**macOS / Linux**

```bash
python3.10 -m venv env
source env/bin/activate
```

2. Update pip and install dependencies

```bash
python -m pip install --upgrade pip
pip install -r requirements.txt
pip install "ultralytics>=8.0,<9"
```

3. Prepare data folders (if not present)

```bash
mkdir -p data/training_videos data/training_vol data/models
```

---

## âš™ï¸ Training the behaviour model (optional)

If you already have `data/models/behavior_model*.{h5,json}` you can skip training.

```bash
python train_dataset.py
```

This creates:

* `data/models/behavior_model.weights.h5`
* `data/models/behavior_model_config.json`

**Notes**

* Training uses `tf.data` sliding windows (memoryâ€‘safe). Adjust the sequence length (T) inside `train_dataset.py` consistently with `app.py`.
* Default sequence length used by the codebase: **16 frames** (changeable).

---

## â–¶ï¸ Run the Streamlit app

```bash
streamlit run app.py
```

In the browser UI:

* Set **Sequence length (frames)** to the trained value (default: `16`).
* Adjust **YOLO confidence** (try `0.35â€“0.50`) if detections are missing or noisy.
* Upload a video and click **Run**.
* Toggle **Red flash on anomaly** and set **Flash duration (frames)** to taste.
* Enable **FPS limit** on lowâ€‘power CPUs for smoother UI.

---

## ðŸ³ Docker (CPUâ€‘only)

**Build** (project root where `Dockerfile` & `requirements.txt` live):

```bash
docker build -t ai-surveillance:cpu .
```

**Run** (mount `data/` into container):

**Windows PowerShell** (use ABSOLUTE path):

```powershell
docker run --rm -p 8501:8501 ^
  -v "C:\full\path\to\project\data:/app/data" ^
  ai-surveillance:cpu
```

**macOS / Linux**

```bash
docker run --rm -p 8501:8501 -v "$(pwd)/data:/app/data" ai-surveillance:cpu
```

**Optional: run training inside the container**

```bash
# Windows
docker run --rm -v "C:\full\path\to\project\data:/app/data" ai-surveillance:cpu python train_dataset.py

# macOS/Linux
docker run --rm -v "$(pwd)/data:/app/data" ai-surveillance:cpu python train_dataset.py
```

---

## ðŸ’¡ Usage tips & configurable knobs

* **Sequence length (T)**: must match the length used during training (default `16`). You may change it in both `train_dataset.py` and `app.py` â€” keep them synchronized.
* **YOLO confidence**: lower for weak detections, higher to reduce false positives.
* **Flash duration**: number of frames to show red border on anomaly.
* **FPS limit**: enable to reduce CPU and UI update rate on lowâ€‘end machines.

---

## ðŸž Troubleshooting

**`requirements.txt` not found**

* Run commands from the project root (where the file exists).

**`ModuleNotFoundError: tensorflow`**

```bash
pip install tensorflow==2.15.0
```

**Weights load error / shape mismatch**

* Ensure `behavior_model.py` architecture matches the model used at training time.
* If Keras vs tf.keras mismatch occurs, uninstall standalone Keras packages:

```bash
pip uninstall -y keras keras-nightly keras-tuner
pip install tensorflow==2.15.0
```

**No/weak detections**

* Lower YOLO confidence in the sidebar or use clearer footage.

**Video can't open**

* Reâ€‘encode to H.264 MP4 (e.g., `ffmpeg -i input.mov -c:v libx264 -preset veryfast output.mp4`).

**Docker volume mount issues on Windows**

* Use absolute path and ensure drive sharing is enabled in Docker Desktop.

---

## ðŸ§‘â€ðŸ’» Development (PyCharm / IDE)

* Open the project root (contains `app.py`, `requirements.txt`).
* Create Python 3.10 virtualenv as project interpreter.
* Install dependencies and Ultralytics:

```bash
pip install -r requirements.txt
pip install "ultralytics>=8.0,<9"
```

**Run/Debug configurations**

* Training: Script = `train_dataset.py`; Working dir = project root
* App: Module = `streamlit`; Parameters = `run app.py`; Working dir = project root

---

## ðŸ”¬ Implementation stack

Streamlit, OpenCV, NumPy, Pandas, SciPy, scikitâ€‘learn, TensorFlow 2.15 (tf.keras), Ultralytics YOLO, deepâ€‘sortâ€‘realtime.

---

## âœï¸ Recommended small improvements (future)

* Add a lightweight web socket for lower latency UI streaming.
* Provide a small sample video in `data/training_videos/sample.mp4` for quick demo.
* Add unit tests for `detection.py` and `utils.py` (mock YOLO output).
* Add a small model quantized variant for very lowâ€‘power CPU inference.

---

## ðŸ™‹ Feedback & help

If you want I can:

* ðŸŽ¨ Reformat the README as a shorter oneâ€‘page cheat sheet
* ðŸ§ª Add example `ffmpeg` commands for preprocessing
* ðŸ§© Produce a minimal `docker-compose.yml` and a small sample video

Just tell me which and Iâ€™ll add it.

---

*Made with â¤ï¸ â€” change the sequence length anywhere in the codebase but keep train & runtime in sync.*
